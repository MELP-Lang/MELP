-- lang: en-US
-- syntax: mlp

-- -----------------------------------------------------------------------------
-- Token Module
-- -----------------------------------------------------------------------------
-- Centralized token definitions and lightweight helpers shared by the MLP
-- self-hosting pipeline (lexer + parser + generator). This file only describes
-- data structures and pure helpers; it does not perform any IO.
-- -----------------------------------------------------------------------------

enum TokenType
    TOKEN_EOF

    -- Literal categories
    TOKEN_NUMBER
    TOKEN_STRING
    TOKEN_INTERPOLATED_STRING
    TOKEN_IDENTIFIER
    TOKEN_TRUE
    TOKEN_FALSE
    TOKEN_NULL

    -- Type declarations
    TOKEN_TYPE_NUMERIC
    TOKEN_TYPE_STRING
    TOKEN_TYPE_BOOLEAN

    -- Structural keywords
    TOKEN_PRINT
    TOKEN_IF
    TOKEN_THEN
    TOKEN_ELSE
    TOKEN_WITH
    TOKEN_FUNCTION
    TOKEN_ASYNC
    TOKEN_AWAIT
    TOKEN_YIELD
    TOKEN_RETURN
    TOKEN_WHILE
    TOKEN_YAPI_DO
    TOKEN_WHILE_BITIR    -- while bitir (break)
    TOKEN_WHILE_DEVAM    -- while devam (continue)
    TOKEN_FOR
    TOKEN_TO
    TOKEN_STEP
    TOKEN_END
    TOKEN_END_IF
    TOKEN_END_WHILE
    TOKEN_END_FOR
    TOKEN_END_FUNCTION
    TOKEN_END_STRUCT
    TOKEN_END_ENUM
    TOKEN_END_SWITCH

    TOKEN_YAPI_STRUCT
    TOKEN_LIST
    TOKEN_OPTIONAL
    TOKEN_MAP

    TOKEN_YAPI_ENUM
    TOKEN_YAPI_SWITCH
    TOKEN_YAPI_CASE
    TOKEN_YAPI_DEFAULT
    TOKEN_MATCH

    TOKEN_TRY
    TOKEN_CATCH
    TOKEN_THROW
    TOKEN_DEFER
    TOKEN_PANIC

    TOKEN_CONST
    TOKEN_TYPEOF
    TOKEN_TYPE
    TOKEN_AS
    TOKEN_IMPORT

    -- Lambda
    TOKEN_LAMBDA
    TOKEN_ARROW

    -- Range / for-each helpers
    TOKEN_IN
    TOKEN_RANGE

    -- Built-in function groups ------------------------------------------------
    TOKEN_BUILTIN_READ_FILE
    TOKEN_BUILTIN_WRITE_FILE
    TOKEN_BUILTIN_APPEND_FILE
    TOKEN_BUILTIN_FILE_EXISTS
    TOKEN_BUILTIN_FILE_SIZE
    TOKEN_BUILTIN_READ_LINES

    TOKEN_BUILTIN_STRING_SPLIT
    TOKEN_BUILTIN_STRING_JOIN
    TOKEN_BUILTIN_STRING_REPLACE
    TOKEN_BUILTIN_STRING_TRIM
    TOKEN_BUILTIN_STRING_UPPER
    TOKEN_BUILTIN_STRING_LOWER
    TOKEN_BUILTIN_STRING_FIND
    TOKEN_BUILTIN_STRING_STARTS_WITH
    TOKEN_BUILTIN_STRING_ENDS_WITH

    TOKEN_BUILTIN_INT_TO_STRING
    TOKEN_BUILTIN_STRING_TO_INT
    TOKEN_BUILTIN_CHAR_TO_STRING
    TOKEN_BUILTIN_STRING_CONCAT

    TOKEN_BUILTIN_NUM
    TOKEN_BUILTIN_STR
    TOKEN_BUILTIN_READ_INPUT
    TOKEN_BUILTIN_READ_LINE
    TOKEN_BUILTIN_READ_INT

    TOKEN_BUILTIN_MATH_ABS
    TOKEN_BUILTIN_MATH_MIN
    TOKEN_BUILTIN_MATH_MAX
    TOKEN_BUILTIN_MATH_POW

    TOKEN_BUILTIN_STRING_LENGTH
    TOKEN_BUILTIN_STRING_SUBSTRING
    TOKEN_BUILTIN_STRING_INDEX_OF
    TOKEN_BUILTIN_STRING_LAST_INDEX_OF

    TOKEN_BUILTIN_LEN
    TOKEN_BUILTIN_ORD
    TOKEN_BUILTIN_CHR
    TOKEN_BUILTIN_CHAR_CODE
    TOKEN_BUILTIN_CHAR_AT
    TOKEN_BUILTIN_SUBSTRING
    TOKEN_BUILTIN_CONTAINS
    TOKEN_BUILTIN_STARTSWITH
    TOKEN_BUILTIN_ENDSWITH
    TOKEN_BUILTIN_LEFT
    TOKEN_BUILTIN_RIGHT
    TOKEN_BUILTIN_MID

    TOKEN_BUILTIN_EXIT_WITH_CODE
    TOKEN_BUILTIN_PANIC
    TOKEN_BUILTIN_ASSERT
    TOKEN_BUILTIN_GET_ERROR_CODE
    TOKEN_BUILTIN_SET_ERROR_CODE

    TOKEN_BUILTIN_MLP_MALLOC
    TOKEN_BUILTIN_MLP_FREE
    TOKEN_BUILTIN_MLP_REALLOC
    TOKEN_BUILTIN_MLP_CALLOC
    TOKEN_BUILTIN_GET_ALLOCATED_BYTES
    TOKEN_BUILTIN_CHECK_MEMORY_LEAKS

    TOKEN_BUILTIN_GET_ENV
    TOKEN_BUILTIN_CURRENT_TIMESTAMP
    TOKEN_BUILTIN_SLEEP_MS

    TOKEN_BUILTIN_READ_BINARY
    TOKEN_BUILTIN_WRITE_BINARY
    TOKEN_BUILTIN_GET_FILE_INFO
    TOKEN_BUILTIN_COPY_FILE

    TOKEN_BUILTIN_LIST_DIRECTORY
    TOKEN_BUILTIN_CREATE_DIRECTORY
    TOKEN_BUILTIN_REMOVE_DIRECTORY
    TOKEN_BUILTIN_DIRECTORY_EXISTS
    TOKEN_BUILTIN_GET_CURRENT_DIR
    TOKEN_BUILTIN_CHANGE_DIRECTORY

    TOKEN_BUILTIN_EXECUTE_COMMAND
    TOKEN_BUILTIN_GET_COMMAND_OUTPUT
    TOKEN_BUILTIN_GET_PROCESS_ID
    TOKEN_BUILTIN_GET_PARENT_PROCESS_ID

    TOKEN_BUILTIN_FORMAT_TIMESTAMP
    TOKEN_BUILTIN_PARSE_TIMESTAMP
    TOKEN_BUILTIN_GET_MILLISECONDS
    TOKEN_BUILTIN_GET_TIME_STRING

    TOKEN_BUILTIN_JOIN_PATH
    TOKEN_BUILTIN_GET_FILE_EXTENSION
    TOKEN_BUILTIN_GET_FILE_NAME
    TOKEN_BUILTIN_GET_DIRECTORY

    -- Delimiters / operators --------------------------------------------------
    TOKEN_LEFT_PAREN
    TOKEN_RIGHT_PAREN
    TOKEN_LEFT_BRACKET
    TOKEN_RIGHT_BRACKET
    TOKEN_LEFT_BRACE
    TOKEN_RIGHT_BRACE
    TOKEN_COMMA
    TOKEN_ASSIGN
    TOKEN_SEMICOLON
    TOKEN_DOT
    TOKEN_COLON

    TOKEN_PLUS
    TOKEN_MINUS
    TOKEN_MUL
    TOKEN_DIV
    TOKEN_GT
    TOKEN_LT

    TOKEN_OP_ESIT_KARSILASTIRMA
    TOKEN_NOT_ESIT
    TOKEN_GTE
    TOKEN_LTE
    TOKEN_MOD
    TOKEN_AND
    TOKEN_OR
    TOKEN_NOT

    TOKEN_BITWISE_AND
    TOKEN_BITWISE_OR
    TOKEN_BITWISE_XOR
    TOKEN_BITWISE_NOT
    TOKEN_LSHIFT
    TOKEN_RSHIFT

    TOKEN_PLUS_ASSIGN
    TOKEN_MINUS_ASSIGN
    TOKEN_MUL_ASSIGN
    TOKEN_DIV_ASSIGN
    TOKEN_INCREMENT
    TOKEN_DECREMENT

    TOKEN_TERNARY_QUESTION
    TOKEN_STOP
    TOKEN_GOTO
    TOKEN_LABEL
end_enum

-- -----------------------------------------------------------------------------
-- Core token structures
-- -----------------------------------------------------------------------------

struct Token
    TokenType type
    String lexeme
    Numeric line
    Numeric column
    list interpolation_parts
end_struct

struct TokenStream
    list tokens
    Numeric index
end_struct

struct TokenStreamTakeResult
    Token token
    TokenStream stream
end_struct

-- -----------------------------------------------------------------------------
-- Factory helpers
-- -----------------------------------------------------------------------------

function make_token(token_type; lexeme; line; column)
    Token token
    token.type = token_type
    token.lexeme = lexeme
    token.line = line
    token.column = column
    token.interpolation_parts = mlp_list_create()
    return token
end_function

function make_interpolated_token(token_type; lexeme; line; column; parts)
    Token token
    token = make_token(token_type; lexeme; line; column)
    if mlp_list_length(parts) > 0 then
        token.interpolation_parts = parts
    end_if
    return token
end_function

function token_stream_create(token_list)
    TokenStream stream
    stream.tokens = token_list
    stream.index = 0
    return stream
end_function

function token_stream_is_end(stream)
    if stream.index >= mlp_list_length(stream.tokens) then
        return 1
    end_if
    return 0
end_function

function token_stream_peek(stream)
    if token_stream_is_end(stream) == 1 then
        return make_token(TOKEN_EOF; ""; 0; 0)
    end_if

    return mlp_list_get(stream.tokens; stream.index)
end_function

function token_stream_take(stream)
    TokenStreamTakeResult result
    result.token = token_stream_peek(stream)

    TokenStream next_stream
    next_stream = stream
    if token_stream_is_end(stream) == 0 then
        next_stream.index = next_stream.index + 1
    end_if

    result.stream = next_stream
    return result
end_function

function token_stream_expect(stream; expected_type)
    TokenStreamTakeResult take
    take = token_stream_take(stream)
    Token current_token
    current_token = take.token
    if current_token.type != expected_type then
        print "Token mismatch. Expected: "
        print expected_type
        print " but got: "
        print current_token.type
        panic("token_stream_expect: unexpected token")
    end_if
    return take
end_function

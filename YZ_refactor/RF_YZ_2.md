# RF_YZ_2: Lexer Refactor - PMPL Keywords

**BaÅŸlangÄ±Ã§:** 14 AralÄ±k 2025  
**GÃ¶rev:** PMPL underscore keyword tokenization  
**Durum:** ðŸŸ¡ IN PROGRESS

---

## ðŸŽ¯ GÃ¶rev TanÄ±mÄ±

Lexer'a PMPL underscore keyword'lerini tanÄ±tmak.

**AmaÃ§:** Normalize edilmiÅŸ PMPL input'u tek token'lara Ã§evirmek.

**Ã–rnek:**
```
INPUT:  "end_if"       â†’ TOKEN: TOKEN_END_IF (tek token!)
INPUT:  "else_if"      â†’ TOKEN: TOKEN_ELSE_IF (tek token!)
INPUT:  "exit_for"     â†’ TOKEN: TOKEN_EXIT_FOR (tek token!)
```

---

## ðŸ“‹ YapÄ±lacaklar

### Faz 1: Token Enum'larÄ±
- [ ] `lexer.h` - TOKEN_END_IF, TOKEN_END_WHILE, vb. ekle
- [ ] TÃ¼m 22 PMPL keyword iÃ§in token tanÄ±mÄ±

### Faz 2: Keyword Recognition
- [ ] `lexer.c` - strcmp ile underscore keyword'leri tanÄ±
- [ ] ESKÄ° iki-kelimelik pattern matching kodunu KALDIR

### Faz 3: Testing
- [ ] `test_lexer.c` - Unit testler oluÅŸtur
- [ ] TÃ¼m PMPL keyword'lerin doÄŸru tokenize edildiÄŸini doÄŸrula

---

## ðŸ”§ Ä°mplementasyon DetaylarÄ±

### Yeni Token'lar (22 adet)

**Block Terminators:**
- TOKEN_END_IF
- TOKEN_END_WHILE
- TOKEN_END_FOR
- TOKEN_END_FUNCTION
- TOKEN_END_STRUCT
- TOKEN_END_SWITCH
- TOKEN_END_MATCH
- TOKEN_END_OPERATOR
- TOKEN_END_TRY

**Control Flow:**
- TOKEN_ELSE_IF

**Loop Control:**
- TOKEN_EXIT_IF
- TOKEN_EXIT_FOR
- TOKEN_EXIT_WHILE
- TOKEN_EXIT_FUNCTION
- TOKEN_EXIT_SWITCH
- TOKEN_CONTINUE_FOR
- TOKEN_CONTINUE_WHILE

**Debug Keywords:**
- TOKEN_DEBUG_GOTO
- TOKEN_DEBUG_PAUSE
- TOKEN_DEBUG_LABEL
- TOKEN_DEBUG_PRINT

**State Keywords:**
- TOKEN_SHARED_STATE

---

## ðŸ§ª Test PlanÄ±

```c
// test_lexer.c taslaÄŸÄ±

void test_block_terminators() {
    assert(tokenize("end_if") == TOKEN_END_IF);
    assert(tokenize("end_while") == TOKEN_END_WHILE);
    // ... 9 test
}

void test_control_flow() {
    assert(tokenize("else_if") == TOKEN_ELSE_IF);
}

void test_loop_control() {
    assert(tokenize("exit_for") == TOKEN_EXIT_FOR);
    assert(tokenize("continue_while") == TOKEN_CONTINUE_WHILE);
    // ... 7 test
}

void test_debug_keywords() {
    assert(tokenize("debug_goto") == TOKEN_DEBUG_GOTO);
    // ... 4 test
}

void test_state_keywords() {
    assert(tokenize("shared_state") == TOKEN_SHARED_STATE);
}
```

**Toplam:** ~25 test

---

## ðŸ’¡ KarÅŸÄ±laÅŸÄ±lan Sorunlar ve Ã‡Ã¶zÃ¼mler

### Sorun 1: Include Path
**Problem:** test_lexer.c'de `#include "../lexer.h"` hata verdi  
**Ã‡Ã¶zÃ¼m:** `#include "lexer.h"` ve `-I.` flag'i kullanÄ±ldÄ±

### Sorun 2: Token Enum SÄ±ralamasÄ±
**Problem:** Yeni token'lar nereye eklenmeli?  
**Ã‡Ã¶zÃ¼m:** Mevcut TOKEN_EXIT'ten sonra, PMPL grubu olarak eklendi

---

## ðŸ“Š Code Metrics

**Dosyalar:**
- lexer.h: +44 satÄ±r (22 token enum)
- lexer.c: +45 satÄ±r (22 keyword check)
- test_lexer.c: ~150 satÄ±r (28 test)

**Toplam:** ~240 satÄ±r yeni kod

---

## âœ… BaÅŸarÄ± Kriterleri

- [x] TÃ¼m 22 token tanÄ±mÄ± eklendi
- [x] Lexer keyword recognition gÃ¼ncellendi
- [x] Test suite 28/28 geÃ§ti
- [x] Mevcut lexer testleri bozulmadÄ± (backward compatible)
- [x] PMPL keywords tek token olarak tanÄ±nÄ±yor

---

## ðŸš€ SonuÃ§

Lexer artÄ±k PMPL underscore keyword'lerini tek token olarak tanÄ±yor!

**Ã–nce:**
```
"end if" â†’ TOKEN_END + TOKEN_IF (iki token, parser hack gerekir)
```

**Sonra:**
```
"end_if" â†’ TOKEN_END_IF (tek token, basit parser!)
```

**BitiÅŸ:** 14 AralÄ±k 2025  
**Test Sonucu:** âœ… PASS (28/28)  
**Commit:** [yakÄ±nda]  
**Durum:** ðŸŸ¢ COMPLETE
